{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{autolink-concat}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- no-set-nb-cells -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic amplitude models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amplitude analysis attempts to describe the intensity distributions that we observe in particle collider experiments in order to extract parameters about intermediate states appearing in the scattering process. The scattering processes that take place in these experiments are governed by the electroweak force and the strong force. The strong force can be described by Quantum Chromodynamics, which exhibits complicated behavior in the low-energy regime.\n",
    "\n",
    "The complicated nature of the strong force makes it difficult to derive intensity models from first principles. Instead, we have to rely on approximations given specific assumptions for the scattering process that we study. Each amplitude model that we formulate is almost always merely an approximation of the true scattering process. As a consequence, we always have to reassess our analysis results and try alternative models. In addition, amplitude models can be extremely complicated, with large, complex-valued parametrizations and dozens of input parameters. We therefore want to evaluate these models with as much information as possible. That means large input data samples and 'fits' using the full likelihood function.\n",
    "\n",
    "Given these challenges, we can identify **three major requirements that amplitude analysis software should satisfy**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{card} {material-regular}`speed` Performance\n",
    ":link: performance\n",
    ":link-type: ref\n",
    "We want to evaluate likelihood function as fast as possible over large data samples, so that we can optimize our model parameters for several hypotheses.\n",
    ":::\n",
    "\n",
    ":::{card} {material-regular}`draw` Flexibility\n",
    ":link: flexibility\n",
    ":link-type: ref\n",
    "We want to quickly formulate a wide range of amplitude models, given the latest theoretical and experimental insights.\n",
    ":::\n",
    "\n",
    ":::{card} {material-regular}`school` Transparency\n",
    ":link: transparency\n",
    ":link-type: ref\n",
    "It must be easy to understand the mathematics behind the implemented model, so that the analysis can be reproduced or compared to comparable experiments.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(performance)=\n",
    "## {material-regular}`speed` Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array-oriented programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Even though Python is a popular programming language for data science, it is too slow for performing computations over large data samples. Computations in Python programs are therefore almost always outsourced through third-party Python libraries that are written in C++ or other compiled languages. This leads to a programming style that we can call **array-oriented programming**. Variables now represent multidimensional arrays and the computational backend performs the element-wise operations behind-the-scenes. This has the additional benefit that the higher level Python code becomes more readable.\n",
    "\n",
    "In the following example, we have two data samples $a$ and $b$, each containing a million data points, and we want to compute $c_i=a_i+b_i^2$ for each of these data point&nbsp;$i$. For simplicity, we set $a$ and $b$ to be `[0, 1, 2, ..., 999_999]` and `[999_999, 999_998, ..., 1, 0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_lst = list(range(1_000_000))\n",
    "b_lst = list(reversed(range(1_000_000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Pure Python loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Naively, one could compute $c$ for each data point by creating a list and filling it with $c_i = a_i+b_i^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "c_lst = []\n",
    "for a_i, b_i in zip(a_lst, a_lst):\n",
    "    c_lst.append(a_i + b_i**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For loops like these are a natural choice when coming from compiled languages like C++, but is considerably much slower when done with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Array-oriented computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[NumPy](https://numpy.org) is one of the most popular array-oriented libraries for Python. The data points for $a$ and $b$ are now represented by array objects..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array(a_lst)\n",
    "b = np.array(b_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "...and our _array-oriented_ computation of $c = a+b^2$ becomes much **faster** and **more readable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "c = a + b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(flexibility)=\n",
    "## {material-regular}`draw` Flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Algebra System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic expressions as template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(transparency)=\n",
    "## {material-regular}`school` Transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-documenting workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Model preservation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We believe that formulating amplitude models symbolically with a Computer Algebra System has several benefits for the amplitude analysis community:\n",
    "\n",
    "- **Amplitude analyses become reproducible, extendable, and portable:**\n",
    "  - Implemented amplitude models are transparently shared as mathematical formulas in a [self-documenting workflow](#self-documenting-workflow). This allows others to reimplement those models with their own framework of choice, or any time in the future when upcoming languages or libraries make the implementation of the analysis outdated.\n",
    "  - The Python ecosystem in combination with Jupyter Notebooks and Sphinx makes it possible to directly rerun analysis in the browser or in some virtual environment locally. [Pinned dependencies](https://github.com/ComPWA/update-pip-constraints) ensure that the analysis produces the same results.\n",
    "\n",
    "- **Lower entry level and knowledge sharing**:<br>\n",
    "  It becomes much easier to share and maintain knowledge gained about amplitude models and amplitude analysis theory. Symbolic amplitude models directly show the implemented mathematics and their numerical functions can directly be used for interactive visualizations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
